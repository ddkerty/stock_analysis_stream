# stock_analysis.py (if __name__ == "__main__" ë¸”ë¡ SyntaxError ìˆ˜ì •)

import os
import logging
import pandas as pd
import numpy as np
import yfinance as yf
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from textblob import TextBlob
import requests
from prophet import Prophet
from prophet.plot import plot_plotly
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from dotenv import load_dotenv
from fredapi import Fred
import traceback
from prophet.diagnostics import cross_validation, performance_metrics
from prophet.plot import plot_cross_validation_metric
import matplotlib.pyplot as plt
import warnings
import locale
import re

warnings.simplefilter(action='ignore', category=FutureWarning)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

try:
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
except NameError:
    BASE_DIR = os.getcwd()
    logging.info(f"__file__ ë³€ìˆ˜ ì—†ìŒ. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì‚¬ìš©: {BASE_DIR}")

CHARTS_FOLDER = os.path.join(BASE_DIR, "charts")
DATA_FOLDER = os.path.join(BASE_DIR, "data")
FORECAST_FOLDER = os.path.join(BASE_DIR, "forecast")

try:
    dotenv_path = os.path.join(BASE_DIR, '.env')
    if os.path.exists(dotenv_path): load_dotenv(dotenv_path=dotenv_path); logging.info(f".env ë¡œë“œ ì„±ê³µ: {dotenv_path}")
    else: logging.warning(f".env íŒŒì¼ ì—†ìŒ: {dotenv_path}")
except Exception as e: logging.error(f".env ë¡œë“œ ì˜¤ë¥˜: {e}")

NEWS_API_KEY = os.getenv("NEWS_API_KEY")
FRED_API_KEY = os.getenv("FRED_API_KEY")

if not NEWS_API_KEY: logging.warning("NEWS_API_KEY ì—†ìŒ.")
if not FRED_API_KEY: logging.warning("FRED_API_KEY ì—†ìŒ.")
if NEWS_API_KEY and FRED_API_KEY: logging.info("API í‚¤ ë¡œë“œ ì‹œë„ ì™„ë£Œ.")


# --- ë°ì´í„° ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ë“¤ ---
# get_fear_greed_index, get_stock_data, get_macro_data, get_fundamental_data, find_financial_statement_item, get_operating_margin_trend, get_roe_trend
# í•¨ìˆ˜ë“¤ì€ ì´ì „ ë‹µë³€ì˜ ìµœì¢… ë²„ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤.
# ... (ì´ì „ ë‹µë³€ì—ì„œ ì œê³µëœ í•¨ìˆ˜ ì •ì˜ë“¤ì„ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”) ...
def get_fear_greed_index():
    """ê³µí¬-íƒìš• ì§€ìˆ˜ë¥¼ APIì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    url = "https://api.alternative.me/fng/?limit=1&format=json&date_format=world"
    try:
        response = requests.get(url, timeout=10); response.raise_for_status()
        data = response.json()['data'][0]; value = int(data['value']); classification = data['value_classification']
        logging.info(f"F&G ì„±ê³µ: {value} ({classification})"); return value, classification
    except Exception as e: logging.error(f"F&G ì˜¤ë¥˜: {e}"); return None, None

def get_stock_data(ticker, start_date=None, end_date=None, period="1y"):
    """ì§€ì •ëœ ì¢…ëª©ì˜ ì£¼ê°€ ë°ì´í„°ë¥¼ yfinanceë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        stock = yf.Ticker(ticker)
        if start_date and end_date: data = stock.history(start=start_date, end=end_date); logging.info(f"{ticker} ì£¼ê°€ ì„±ê³µ ({start_date}~{end_date})")
        else: data = stock.history(period=period); logging.info(f"{ticker} ì£¼ê°€ ì„±ê³µ (ê¸°ê°„: {period})")
        if data.empty: logging.warning(f"{ticker} ì£¼ê°€ ë°ì´í„° ë¹„ì–´ìˆìŒ."); return None
        if isinstance(data.index, pd.DatetimeIndex): data.index = data.index.tz_localize(None)
        return data
    except Exception as e: logging.error(f"í‹°ì»¤ '{ticker}' ì£¼ê°€ ë°ì´í„° ì‹¤íŒ¨: {e}"); return None

def get_macro_data(start_date, end_date=None, fred_key=None):
    """VIX, US10Y, 13ì£¼ êµ­ì±„(IRX), DXY, ì—°ë°©ê¸°ê¸ˆ ê¸ˆë¦¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if end_date is None: end_date = datetime.today().strftime("%Y-%m-%d")
    tickers = {"^VIX": "VIX", "^TNX": "US10Y", "^IRX": "US13W", "DX-Y.NYB": "DXY"}; df_macro = pd.DataFrame()
    all_yf_data = []
    for tk, label in tickers.items():
        try:
            tmp = yf.download(tk, start=start_date, end=end_date, progress=False, timeout=10)
            if not tmp.empty:
                tmp = tmp[['Close']].rename(columns={"Close": label})
                if isinstance(tmp.index, pd.DatetimeIndex): tmp.index = tmp.index.tz_localize(None)
                all_yf_data.append(tmp); logging.info(f"{label} ë°ì´í„° ì„±ê³µ")
            else: logging.warning(f"{label} ë°ì´í„° ë¹„ì–´ìˆìŒ.")
        except Exception as e: logging.error(f"{label} ë°ì´í„° ì‹¤íŒ¨: {e}")
    if all_yf_data:
        df_macro = pd.concat(all_yf_data, axis=1)
        if isinstance(df_macro.columns, pd.MultiIndex): df_macro.columns = df_macro.columns.get_level_values(-1)
    if fred_key:
        try:
            fred = Fred(api_key=fred_key); fedfunds = fred.get_series("FEDFUNDS", start_date=start_date, end_date=end_date).rename("FedFunds")
            if isinstance(fedfunds.index, pd.DatetimeIndex): fedfunds.index = fedfunds.index.tz_localize(None)
            if not df_macro.empty: df_macro = df_macro.merge(fedfunds, left_index=True, right_index=True, how='outer')
            else: df_macro = pd.DataFrame(fedfunds)
            logging.info("FRED ë°ì´í„° ë³‘í•©/ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")
        except Exception as e: logging.error(f"FRED ë°ì´í„° ì‹¤íŒ¨: {e}");
    else: logging.warning("FRED í‚¤ ì—†ì–´ FRED ë°ì´í„° ìŠ¤í‚µ.")
    if not df_macro.empty:
        if 'FedFunds' not in df_macro.columns: df_macro['FedFunds'] = pd.NA
        df_macro.index = pd.to_datetime(df_macro.index).tz_localize(None)
        df_macro = df_macro.sort_index().ffill().bfill().reset_index().rename(columns={'index': 'Date'}); df_macro["Date"] = pd.to_datetime(df_macro["Date"])
        logging.info("ë§¤í¬ë¡œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ."); return df_macro
    else: logging.warning("ë§¤í¬ë¡œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨."); return pd.DataFrame()

def format_market_cap(mc):
    """ì‹œê°€ì´ì•¡ ìˆ«ìë¥¼ ì½ê¸° ì‰¬ìš´ ë¬¸ìì—´(T/B/M ë‹¨ìœ„)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if isinstance(mc, (int, float)) and mc > 0:
        if mc >= 1e12: return f"${mc / 1e12:.2f} T"
        elif mc >= 1e9: return f"${mc / 1e9:.2f} B"
        elif mc >= 1e6: return f"${mc / 1e6:.2f} M"
        else: return f"${mc:,.0f}"
    return "N/A"

def get_fundamental_data(ticker):
    """yfinanceì˜ .infoë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ìš” ê¸°ë³¸ì  ë¶„ì„ ì§€í‘œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    logging.info(f"{ticker}: ê¸°ë³¸ ì •ë³´(.info) ê°€ì ¸ì˜¤ê¸° ì‹œë„...")
    fundamentals = {key: "N/A" for key in ["ì‹œê°€ì´ì•¡", "PER", "EPS", "ë°°ë‹¹ìˆ˜ìµë¥ ", "ë² íƒ€", "ì—…ì¢…", "ì‚°ì—…", "ìš”ì•½"]}
    try:
        stock = yf.Ticker(ticker); info = stock.info
        if not info or info.get('regularMarketPrice') is None: logging.warning(f"'{ticker}' ìœ íš¨ .info ë°ì´í„° ì—†ìŒ."); return fundamentals
        fundamentals["ì‹œê°€ì´ì•¡"] = format_market_cap(info.get("marketCap"))
        fwd_pe = info.get('forwardPE'); trl_pe = info.get('trailingPE')
        if isinstance(fwd_pe, (int, float)): fundamentals["PER"] = f"{fwd_pe:.2f} (Forward)"
        elif isinstance(trl_pe, (int, float)): fundamentals["PER"] = f"{trl_pe:.2f} (Trailing)"
        eps_val = info.get('trailingEps'); fundamentals["EPS"] = f"{eps_val:.2f}" if isinstance(eps_val, (int, float)) else "N/A"
        div_yield = info.get('dividendYield'); fundamentals["ë°°ë‹¹ìˆ˜ìµë¥ "] = f"{div_yield * 100:.2f}%" if isinstance(div_yield, (int, float)) and div_yield > 0 else "N/A"
        beta_val = info.get('beta'); fundamentals["ë² íƒ€"] = f"{beta_val:.2f}" if isinstance(beta_val, (int, float)) else "N/A"
        fundamentals["ì—…ì¢…"] = info.get("sector", "N/A"); fundamentals["ì‚°ì—…"] = info.get("industry", "N/A"); fundamentals["ìš”ì•½"] = info.get("longBusinessSummary", "N/A")
        logging.info(f"{ticker} ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ."); return fundamentals
    except Exception as e: logging.error(f"{ticker} ê¸°ë³¸ ì •ë³´(.info) ì‹¤íŒ¨: {e}"); return fundamentals

def find_financial_statement_item(index, keywords, contains_mode=True, case_sensitive=False):
    """ì¬ë¬´ì œí‘œ ì¸ë±ìŠ¤ì—ì„œ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ê±°ë‚˜ ì¼ì¹˜í•˜ëŠ” í•­ëª© ì´ë¦„ì„ ì°¾ìŠµë‹ˆë‹¤."""
    if not isinstance(index, pd.Index): return None
    pattern = r'\s*'.join(keywords); flags = 0 if case_sensitive else re.IGNORECASE
    for item in index:
        item_str = str(item) # Ensure item is string for regex
        if contains_mode:
             try:
                  if re.search(pattern, item_str, flags=flags): return item
             except TypeError: continue
        else:
            cleaned_item = re.sub(r'\W+', '', item_str).lower(); cleaned_pattern = re.sub(r'\W+', '', ''.join(keywords)).lower()
            if cleaned_item == cleaned_pattern: return item
    first_keyword_pattern = keywords[0]
    for item in index:
         item_str = str(item)
         try:
              if re.search(first_keyword_pattern, item_str, flags=flags): logging.warning(f"ì •í™• í•­ëª©ëª… ë§¤ì¹­ ì‹¤íŒ¨. '{keywords}' ëŒ€ì‹  '{item}' ì‹œë„."); return item
         except TypeError: continue
    return None

def get_roe_trend(ticker, num_periods=4):
    """ìµœê·¼ ë¶„ê¸°ë³„ ROE(%) ì¶”ì„¸ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤ (ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)."""
    logging.info(f"{ticker}: ë¶„ê¸°ë³„ ROE ì¶”ì„¸ ê°€ì ¸ì˜¤ê¸° ì‹œë„ (ìµœê·¼ {num_periods} ë¶„ê¸°)...")
    try:
        stock = yf.Ticker(ticker)
        qf = stock.quarterly_financials; qbs = stock.quarterly_balance_sheet
        if qf.empty or qbs.empty: logging.warning(f"{ticker}: ë¶„ê¸° ì¬ë¬´/ëŒ€ì°¨ëŒ€ì¡°í‘œ ë°ì´í„° ì—†ìŒ."); return None
        net_income_col = find_financial_statement_item(qf.index, ['Net', 'Income'])
        equity_col = find_financial_statement_item(qbs.index, ['Stockholder', 'Equity']) or find_financial_statement_item(qbs.index, ['Total', 'Equity', 'Gross'])
        if not net_income_col or not equity_col: logging.warning(f"{ticker}: ìˆœì´ìµ('{net_income_col}') ë˜ëŠ” ìë³¸ì´ê³„('{equity_col}') í•­ëª© ì°¾ê¸° ì‹¤íŒ¨."); return None
        qf_recent = qf.loc[[net_income_col]].iloc[:, :num_periods].T
        qbs_recent = qbs.loc[[equity_col]].iloc[:, :num_periods].T
        df_trend = pd.merge(qf_recent, qbs_recent, left_index=True, right_index=True, how='outer')
        df_trend.index = pd.to_datetime(df_trend.index); df_trend = df_trend.sort_index(ascending=True)
        df_trend[net_income_col] = pd.to_numeric(df_trend[net_income_col], errors='coerce')
        df_trend[equity_col] = pd.to_numeric(df_trend[equity_col], errors='coerce')
        df_trend[equity_col] = df_trend[equity_col].apply(lambda x: x if pd.notna(x) and x > 0 else np.nan) # NaN ì²´í¬ ì¶”ê°€
        df_trend.dropna(subset=[net_income_col, equity_col], inplace=True)
        if df_trend.empty: logging.warning(f"{ticker}: ROE ê³„ì‚° ê°€ëŠ¥ ë°ì´í„° ë¶€ì¡±."); return None
        df_trend['ROE (%)'] = (df_trend[net_income_col] / df_trend[equity_col]) * 100; df_trend['ROE (%)'] = df_trend['ROE (%)'].round(2)
        result_trend = df_trend[['ROE (%)']].reset_index().rename(columns={'index': 'Date'})
        result_trend['Date'] = result_trend['Date'].dt.strftime('%Y-%m-%d')
        logging.info(f"{ticker}: ìµœê·¼ {len(result_trend)}ê°œ ë¶„ê¸° ROE(%) ì¶”ì„¸ ê³„ì‚° ì™„ë£Œ."); return result_trend.to_dict('records')
    except Exception as e: logging.error(f"{ticker}: ROE ì¶”ì„¸ ê³„ì‚° ì˜¤ë¥˜: {e}"); return None

def get_operating_margin_trend(ticker, num_periods=4):
    """ìµœê·¼ ë¶„ê¸°ë³„ ì˜ì—…ì´ìµë¥  ì¶”ì„¸ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤ (ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)."""
    logging.info(f"{ticker}: ë¶„ê¸°ë³„ ì˜ì—…ì´ìµë¥  ì¶”ì„¸ ê°€ì ¸ì˜¤ê¸° ì‹œë„ (ìµœê·¼ {num_periods} ë¶„ê¸°)...")
    try:
        stock = yf.Ticker(ticker); qf = stock.quarterly_financials
        if qf.empty: logging.warning(f"{ticker}: ë¶„ê¸° ì¬ë¬´ ë°ì´í„° ì—†ìŒ."); return None
        revenue_col = find_financial_statement_item(qf.index, ['Total', 'Revenue']) or find_financial_statement_item(qf.index, ['Revenue'])
        op_income_col = find_financial_statement_item(qf.index, ['Operating', 'Income']) or find_financial_statement_item(qf.index, ['OperatingIncome'])
        if not revenue_col or not op_income_col: logging.warning(f"{ticker}: ë§¤ì¶œ/ì˜ì—…ì´ìµ í•­ëª© ì°¾ê¸° ì‹¤íŒ¨."); return None
        qf_recent = qf.iloc[:, :num_periods]; df_trend = qf_recent.loc[[revenue_col, op_income_col]].T
        df_trend.index = pd.to_datetime(df_trend.index); df_trend = df_trend.sort_index(ascending=True)
        df_trend[revenue_col] = pd.to_numeric(df_trend[revenue_col], errors='coerce'); df_trend[op_income_col] = pd.to_numeric(df_trend[op_income_col], errors='coerce')
        df_trend.replace(0, np.nan, inplace=True); df_trend.dropna(subset=[revenue_col, op_income_col], inplace=True)
        if df_trend.empty: logging.warning(f"{ticker}: ì˜ì—…ì´ìµë¥  ê³„ì‚° ê°€ëŠ¥ ë°ì´í„° ë¶€ì¡±."); return None
        df_trend['Operating Margin (%)'] = (df_trend[op_income_col] / df_trend[revenue_col]) * 100; df_trend['Operating Margin (%)'] = df_trend['Operating Margin (%)'].round(2)
        result_trend = df_trend[['Operating Margin (%)']].reset_index().rename(columns={'index': 'Date'}); result_trend['Date'] = result_trend['Date'].dt.strftime('%Y-%m-%d')
        logging.info(f"{ticker}: ìµœê·¼ {len(result_trend)}ê°œ ë¶„ê¸° ì˜ì—…ì´ìµë¥  ì¶”ì„¸ ê³„ì‚° ì™„ë£Œ."); return result_trend.to_dict('records')
    except Exception as e: logging.error(f"{ticker}: ì˜ì—…ì´ìµë¥  ì¶”ì„¸ ê³„ì‚° ì˜¤ë¥˜: {e}"); return None

def plot_stock_chart(ticker, start_date=None, end_date=None, period="1y"):
    """ì£¼ê°€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì°¨íŠ¸ Figure ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    df = get_stock_data(ticker, start_date=start_date, end_date=end_date, period=period)
    if df is None or df.empty: logging.error(f"{ticker} ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: ì£¼ê°€ ë°ì´í„° ì—†ìŒ"); return None
    try:
        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.03, row_heights=[0.7, 0.3])
        fig.add_trace(go.Candlestick(x=df.index, open=df['Open'], high=df['High'], low=df['Low'], close=df['Close'], name='ê°€ê²©'), row=1, col=1)
        fig.add_trace(go.Bar(x=df.index, y=df['Volume'], name='ê±°ë˜ëŸ‰', marker_color='rgba(0,0,100,0.6)'), row=2, col=1)
        fig.update_layout(title=f'{ticker} ì£¼ê°€ ë° ê±°ë˜ëŸ‰ ì°¨íŠ¸', yaxis_title='ê°€ê²©', yaxis2_title='ê±°ë˜ëŸ‰', xaxis_rangeslider_visible=False, hovermode='x unified', margin=dict(l=20, r=20, t=40, b=20))
        fig.update_yaxes(title_text="ê°€ê²©", row=1, col=1); fig.update_yaxes(title_text="ê±°ë˜ëŸ‰", row=2, col=1)
        logging.info(f"{ticker} ì°¨íŠ¸ ìƒì„± ì™„ë£Œ (Figure ê°ì²´ ë°˜í™˜)"); return fig
    except Exception as e: logging.error(f"{ticker} ì°¨íŠ¸ Figure ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"); return None

def get_news_sentiment(ticker, api_key):
    """ì§€ì •ëœ ì¢…ëª©ì— ëŒ€í•œ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    if not api_key: logging.warning("NEWS_API_KEY ì—†ìŒ."); return ["ë‰´ìŠ¤ API í‚¤ ë¯¸ì„¤ì •."]
    url = f"https://newsapi.org/v2/everything?q={ticker}&pageSize=20&language=en&sortBy=publishedAt&apiKey={api_key}"
    try:
        response = requests.get(url, timeout=10); response.raise_for_status()
        articles = response.json().get('articles', [])
        if not articles: return ["ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ."]
        output_lines, total_polarity, analyzed_count = [], 0, 0
        for i, article in enumerate(articles, 1):
            title = article.get('title', 'N/A')
            text = article.get('description') or article.get('content') or title or ""
            if text and text != "[Removed]":
                try: blob = TextBlob(text); pol = blob.sentiment.polarity; output_lines.append(f"{i}. {title} | ê°ì •: {pol:.2f}"); total_polarity += pol; analyzed_count += 1
                except Exception as text_err: output_lines.append(f"{i}. {title} | ê°ì • ë¶„ì„ ì˜¤ë¥˜")
            else: output_lines.append(f"{i}. {title} | ë‚´ìš© ì—†ìŒ")
        avg_pol = total_polarity / analyzed_count if analyzed_count > 0 else 0
        logging.info(f"{ticker} ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì™„ë£Œ (í‰ê· : {avg_pol:.2f})"); output_lines.insert(0, f"ì´ {analyzed_count}ê°œ ë‰´ìŠ¤ ë¶„ì„ | í‰ê·  ê°ì„± ì ìˆ˜: {avg_pol:.2f}"); return output_lines
    except requests.exceptions.RequestException as e: return [f"ë‰´ìŠ¤ API ìš”ì²­ ì‹¤íŒ¨: {e}"]
    except Exception as e: logging.error(f"ë‰´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {e}"); return ["ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ."]

def run_prophet_forecast(ticker, start_date, end_date=None, forecast_days=30, fred_key=None):
    """Prophet ì˜ˆì¸¡, êµì°¨ ê²€ì¦ ìˆ˜í–‰ í›„ ì˜ˆì¸¡ ê²°ê³¼(dict), ì˜ˆì¸¡ ì°¨íŠ¸(fig), CVì°¨íŠ¸ ê²½ë¡œ(str) ë°˜í™˜"""
    if end_date is None: end_date = datetime.today().strftime("%Y-%m-%d")
    df_stock = get_stock_data(ticker, start_date=start_date, end_date=end_date)
    if df_stock is None or df_stock.empty: return None, None, None
    df_stock = df_stock.reset_index()[["Date", "Close"]]; df_stock["Date"] = pd.to_datetime(df_stock["Date"])
    df_macro = get_macro_data(start_date=start_date, end_date=end_date, fred_key=fred_key)
    if not df_macro.empty:
        df_stock['Date'] = pd.to_datetime(df_stock['Date']); df_macro['Date'] = pd.to_datetime(df_macro['Date'])
        df_merged = pd.merge(df_stock, df_macro, on="Date", how="left"); logging.info(f"ì£¼ê°€/ë§¤í¬ë¡œ ë°ì´í„° ë³‘í•© ì™„ë£Œ.")
        macro_cols = ["VIX", "US10Y", "US13W", "DXY", "FedFunds"]
        for col in macro_cols:
            if col in df_merged.columns:
                if not pd.api.types.is_numeric_dtype(df_merged[col]): df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')
                df_merged[col] = df_merged[col].ffill().bfill()
    else: logging.warning("ë§¤í¬ë¡œ ë°ì´í„° ì—†ì–´ ì£¼ê°€ ë°ì´í„°ë§Œ ì‚¬ìš©."); df_merged = df_stock
    if df_merged['Close'].isnull().any(): df_merged = df_merged.dropna(subset=['Close'])
    if df_merged.empty or len(df_merged) < 30: logging.error(f"Prophet ì‹¤íŒ¨: ë°ì´í„° ë¶€ì¡± ({len(df_merged)} í–‰)."); return None, None, None
    logging.info(f"Prophet í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(df_merged)} í–‰")
    os.makedirs(DATA_FOLDER, exist_ok=True); data_csv_path = os.path.join(DATA_FOLDER, f"{ticker}_merged_for_prophet.csv")
    try: df_merged.to_csv(data_csv_path, index=False); logging.info(f"í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {data_csv_path}")
    except Exception as save_err: logging.error(f"í•™ìŠµ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {save_err}")
    df_prophet = df_merged.rename(columns={"Date": "ds", "Close": "y"}); df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])
    m = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False, changepoint_prior_scale=0.05)
    regressors = []
    if not df_macro.empty:
        for col in macro_cols:
             if col in df_prophet.columns and pd.api.types.is_numeric_dtype(df_prophet[col]) and df_prophet[col].isnull().sum() == 0:
                 m.add_regressor(col); regressors.append(col); logging.info(f"Regressor ì¶”ê°€: {col}")
             elif col in df_prophet.columns: logging.warning(f"Regressor '{col}' íƒ€ì…/ê²°ì¸¡ì¹˜ ë¬¸ì œë¡œ ì¶”ê°€ ì•ˆ í•¨.")
    forecast_result_dict, fig_forecast, cv_plot_path = None, None, None
    try:
        m.fit(df_prophet[['ds', 'y'] + regressors]); logging.info("Prophet ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.")
        os.makedirs(FORECAST_FOLDER, exist_ok=True)
        try: # Cross-validation block
            initial_days, period_days, horizon_days = '365 days', '90 days', f'{forecast_days} days'
            logging.info(f"Prophet CV ì‹œì‘..."); df_cv = cross_validation(m, initial=initial_days, period=period_days, horizon=horizon_days, parallel=None)
            logging.info("Prophet CV ì™„ë£Œ."); df_p = performance_metrics(df_cv); logging.info(f"Prophet ì„±ëŠ¥ ì§€í‘œ:\n{df_p.head().to_string()}")
            fig_cv = plot_cross_validation_metric(df_cv, metric='mape'); plt.title(f'{ticker} Cross Validation MAPE'); cv_plot_path = os.path.join(FORECAST_FOLDER, f"{ticker}_cv_mape_plot.png")
            fig_cv.savefig(cv_plot_path); plt.close(fig_cv); logging.info(f"CV MAPE ì°¨íŠ¸ ì €ì¥: {cv_plot_path}")
        except Exception as cv_err: logging.error(f"Prophet CV ì˜¤ë¥˜: {cv_err}"); cv_plot_path = None
        logging.info("ë¯¸ë˜ ì˜ˆì¸¡ ì‹œì‘..."); future = m.make_future_dataframe(periods=forecast_days)
        if regressors: # Regressor future value handling
            temp_merged = df_merged.copy(); temp_merged['Date'] = pd.to_datetime(temp_merged['Date'])
            future = future.merge(temp_merged[['Date'] + regressors], left_on='ds', right_on='Date', how='left').drop(columns=['Date'])
            for col in regressors:
                if col in temp_merged.columns:
                    non_na = temp_merged[col].dropna(); last_val = non_na.iloc[-1] if not non_na.empty else 0
                    if non_na.empty: logging.warning(f"Regressor '{col}' ê³¼ê±° ê°’ ëª¨ë‘ NaN.")
                    future[col] = future[col].ffill().fillna(last_val)
        forecast = m.predict(future); logging.info("ë¯¸ë˜ ì˜ˆì¸¡ ì™„ë£Œ.")
        csv_fn = os.path.join(FORECAST_FOLDER, f"{ticker}_forecast_data.csv")
        forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].copy().assign(ds=lambda dfx: dfx['ds'].dt.strftime('%Y-%m-%d')).to_csv(csv_fn, index=False) # lambda df: -> lambda dfx:
        logging.info(f"ì˜ˆì¸¡ ë°ì´í„° ì €ì¥: {csv_fn}")
        fig_forecast = plot_plotly(m, forecast); fig_forecast.update_layout(title=f'{ticker} Price Forecast', margin=dict(l=20, r=20, t=40, b=20)); logging.info(f"ì˜ˆì¸¡ Figure ìƒì„± ì™„ë£Œ.")
        forecast_result_dict = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(forecast_days).to_dict('records')
        for record in forecast_result_dict: record['ds'] = record['ds'].strftime('%Y-%m-%d')
        return forecast_result_dict, fig_forecast, cv_plot_path
    except Exception as e: logging.error(f"Prophet í•™ìŠµ/ì˜ˆì¸¡ ì˜¤ë¥˜: {e}"); logging.error(traceback.format_exc()); return None, None, None


# --- ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ ---

# 7. í†µí•© ë¶„ì„ - num_trend_periods ì¸ì ì¶”ê°€ ë° ì „ë‹¬, roe_trend ì¶”ê°€
def analyze_stock(ticker, news_key, fred_key, analysis_period_years=2, forecast_days=30, num_trend_periods=4): # num_trend_periods ì¶”ê°€
    """ëª¨ë“  ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ì£¼ì‹ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    logging.info(f"--- {ticker} ì£¼ì‹ ë¶„ì„ ì‹œì‘ ---")
    output_results = {}
    try:
        end_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        start_date = end_date - relativedelta(years=analysis_period_years)
        start_date_str = start_date.strftime("%Y-%m-%d"); end_date_str = end_date.strftime("%Y-%m-%d")
        logging.info(f"ë¶„ì„ ê¸°ê°„: {start_date_str} ~ {end_date_str}")
    except Exception as date_err: logging.error(f"ë‚ ì§œ ì„¤ì • ì˜¤ë¥˜: {date_err}"); return None

    df_stock_full = get_stock_data(ticker, start_date=start_date_str, end_date=end_date_str)
    if df_stock_full is not None and not df_stock_full.empty:
        output_results['current_price'] = f"{df_stock_full['Close'].iloc[-1]:.2f}" if not df_stock_full['Close'].empty else "N/A"
        output_results['analysis_period_start'] = start_date_str; output_results['analysis_period_end'] = end_date_str
        output_results['data_points'] = len(df_stock_full)
    else:
        output_results['current_price'] = "N/A"; output_results['analysis_period_start'] = start_date_str
        output_results['analysis_period_end'] = end_date_str; output_results['data_points'] = 0
        logging.warning(f"{ticker} ì£¼ê°€ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨. ë¶„ì„ ì œí•œë¨.")

    stock_chart_fig = plot_stock_chart(ticker, start_date=start_date_str, end_date=end_date_str)
    output_results['stock_chart_fig'] = stock_chart_fig

    output_results['fundamentals'] = get_fundamental_data(ticker)
    output_results['operating_margin_trend'] = get_operating_margin_trend(ticker, num_periods=num_trend_periods)
    # --- ğŸ€ ROE ì¶”ì„¸ ë°ì´í„° ì¶”ê°€ ---
    output_results['roe_trend'] = get_roe_trend(ticker, num_periods=num_trend_periods)
    # -----------------------------

    output_results['news_sentiment'] = get_news_sentiment(ticker, news_key)
    fg_value, fg_class = get_fear_greed_index()
    output_results['fear_greed_index'] = {'value': fg_value, 'classification': fg_class} if fg_value is not None else "N/A"

    if output_results['data_points'] > 30 and output_results['current_price'] != "N/A":
        forecast_dict, forecast_fig, cv_plot_path = run_prophet_forecast(
            ticker, start_date=start_date_str, end_date=end_date_str,
            forecast_days=forecast_days, fred_key=fred_key)
        output_results['prophet_forecast'] = forecast_dict if forecast_dict is not None else "ì˜ˆì¸¡ ì‹¤íŒ¨"
        output_results['forecast_fig'] = forecast_fig; output_results['cv_plot_path'] = cv_plot_path
    else:
         forecast_msg = f"ë°ì´í„° ë¶€ì¡± ({output_results['data_points']}ê°œ)" if output_results['data_points'] <= 30 else "ì£¼ê°€ ì •ë³´ ì—†ìŒ"
         output_results['prophet_forecast'] = f"{forecast_msg}ìœ¼ë¡œ ì˜ˆì¸¡ ë¶ˆê°€"; output_results['forecast_fig'] = None
         output_results['cv_plot_path'] = None; logging.warning(f"{forecast_msg}ìœ¼ë¡œ Prophet ì˜ˆì¸¡ ê±´ë„ˆ<0xEB>ëœ€.")

    logging.info(f"--- {ticker} ì£¼ì‹ ë¶„ì„ ì™„ë£Œ ---")
    return output_results


# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ (ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ìš© - â­ï¸ ìˆ˜ì •ëœ ë¶€ë¶„ í™•ì¸) ---
if __name__ == "__main__":
    print(f"stock_analysis.py ì§ì ‘ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ ëª©ì , Base directory: {BASE_DIR}).")
    target_ticker = "AAPL"
    news_api_key_local = os.getenv("NEWS_API_KEY"); fred_api_key_local = os.getenv("FRED_API_KEY")
    if not news_api_key_local or not fred_api_key_local: print("ê²½ê³ : ë¡œì»¬ í…ŒìŠ¤íŠ¸ API í‚¤ ì—†ìŒ."); test_results = None
    else: test_results = analyze_stock(ticker=target_ticker, news_key=news_api_key_local, fred_key=fred_api_key_local, analysis_period_years=1, forecast_days=15, num_trend_periods=5)
    print("\n--- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ---")
    if test_results:
        for key, value in test_results.items():
            if 'fig' in key and value is not None:
                print(f"- {key.replace('_', ' ').title()}: Plotly Figure ê°ì²´ ìƒì„±ë¨")
            elif key == 'fundamentals' and isinstance(value, dict):
                print(f"- {key.replace('_', ' ').title()}:")
                # í‘œì¤€ for ë°˜ë³µë¬¸ ì‚¬ìš©
                for f_key, f_value in value.items():
                     print(f"    - {f_key}: {f_value}")
            elif key == 'operating_margin_trend' and isinstance(value, list):
                print(f"- {key.replace('_', ' ').title()}: {len(value)} ë¶„ê¸° ë°ì´í„°")
                # í‘œì¤€ for ë°˜ë³µë¬¸ ì‚¬ìš©
                for item in value:
                     print(f"    - {item}")
            elif key == 'roe_trend' and isinstance(value, list): # ROE ì¶œë ¥ ì¶”ê°€
                print(f"- {key.replace('_', ' ').title()}: {len(value)} ë¶„ê¸° ë°ì´í„°")
                # í‘œì¤€ for ë°˜ë³µë¬¸ ì‚¬ìš©
                for item in value:
                     print(f"    - {item}")
            elif key == 'prophet_forecast':
                print(f"- {key.replace('_', ' ').title()}: {type(value)}")
            elif key == 'news_sentiment':
                print(f"- {key.replace('_', ' ').title()}: {len(value) if isinstance(value, list) else 0} í•­ëª©")
            else:
                print(f"- {key.replace('_', ' ').title()}: {value}")
    else: print("í…ŒìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨.")
    print("\n--- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¢…ë£Œ ---")